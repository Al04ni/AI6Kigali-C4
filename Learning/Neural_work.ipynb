{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e8888d-3c5c-4ab5-ac92-dedb1f9010f9",
   "metadata": {},
   "source": [
    "# Building Neural Network from scracth\n",
    "\n",
    "In this notebook, i aim to learn more about neural network as well as building ones along the way.\n",
    "But before we go into the deep about neural network, let's get to know much more about the *`Neural netork`*. Artificial neuron are inspired by biological neurons in our brains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab699b9-0de4-41b3-ac06-e99b89cd073b",
   "metadata": {},
   "source": [
    "## Biological neuron workings: Quick view\n",
    "In our brains, a biologicla neuron receives `signals` from other neurons through structures called `dendrites`, then these signals are processed in the cell body to function, and if the combines signal is strong enough, the `neuron` `fires`, sending a signal through its `axon`(In charge to transmits the electrical impulses, signals or simply the action potentials from the cell body to other neurons) to other neurons.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6cf7b44-01ea-4276-bb87-4607a0705f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Blausen_0657_MultipolarNeuron.png/960px-Blausen_0657_MultipolarNeuron.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the Biological Neuron parts\n",
    "from IPython.display import Image\n",
    "\n",
    "# Link from the Wikipedia\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Blausen_0657_MultipolarNeuron.png/960px-Blausen_0657_MultipolarNeuron.png\"\n",
    "# Display the image\n",
    "Image(url=url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f7b06-da2b-4501-b175-5dd6c5c68250",
   "metadata": {},
   "source": [
    "So here's how Artificial neurons accomplish or in good way mimic this behavior:\n",
    "\n",
    "- `Inputs`: represent the signals received from other neurons.\n",
    "- `Weights`: represent the strength of each connection.\n",
    "- `Bias`: represents the neuron's tendency to fire regardless of the inputs.\n",
    "- `Activation function`: aims to mimincs the firing behavior.\n",
    "  \n",
    "Looks complex, right? And it looks like the simple model however when combined with many other neurons this forms the basis of neural networks that can learn complex patterns and make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e4cd1f-d9dc-47a9-81f3-a49146b2941d",
   "metadata": {},
   "source": [
    "## Mathematical model of a neuron\n",
    "Actually artificial neuron takes `multiple inputs`, then multiplies each by a `corresponding weight`, sums these weighted unputs then adds a `bias` and produce an `output`.\n",
    "\n",
    "Mathematically, Neuron inputs ($x_1$,$x_2$,..., $x_n$) where the output is calculated as:\n",
    "\n",
    "\\begin{aligned}\n",
    "Output = ({w_1} * {x_1}) + ({w_2} x {x_2}) + ... + ({w_n} * {x_n}) + b\n",
    "\\end{aligned}\n",
    "\n",
    "Where:\n",
    "- $x_1$, $x_2$,..., $x_n$ are the input values.\n",
    "- $w_1$, $w_2$,..., $w_n$ are the weights for each input.\n",
    "- b is the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a99114",
   "metadata": {},
   "source": [
    "Basing on my findings the calculation above is also known as `weighted sum` plus `bias`, so simply we can express it more concisely using vector notation:\n",
    "\n",
    "\\begin{aligned}\n",
    "Output = w*x + b\n",
    "\\end{aligned}\n",
    "\n",
    "Where the `w*x` represent the dot product of the weight vector and the input vector.\n",
    "\n",
    "> Think `Weights` as `importance factors`\n",
    "> Which will help us to determine how much `attention` the `neuron` pays to each input and then the `bias` as`threshold adjustement` that makes it `easier or harder` for the neuron to produce a `high output` regardless of the `inputs`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e694ff4b",
   "metadata": {},
   "source": [
    "## Our Neuron class\n",
    "\n",
    "Now things are becoming somehow interesting, so let's get our hands dirty by implementing quick artificial neuron in `Python` using `Numpy` by creating simple `Neuron` class:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50945140-9532-432e-ab38-f72a32b8f8a6",
   "metadata": {},
   "source": [
    "```\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, n_inputs):\n",
    "        \"\"\"\n",
    "        Initialize a neuron.\n",
    "        n_inputs: Number of input features.\n",
    "        \"\"\"\n",
    "        # Initialize weights randomly to break symmetry\n",
    "        self.weights = np.random.rand(n_inputs) * 0.1  # Small values help with training stability\n",
    "        self.bias = 0.0  # Start with zero bias\n",
    "        \n",
    "        print(f\"Neuron initialized with {n_inputs} inputs.\")\n",
    "        print(f\"Initial weights: {self.weights}\")\n",
    "        print(f\"Initial bias: {self.bias}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd47ae4-8466-433d-aa4b-6158d078be80",
   "metadata": {},
   "source": [
    "These codes define our neuron's structure and `__init__` method will initialize our main properties which are:\n",
    "- `Weight`, a random array with one value per inputs, saclaed to be small(random value between 0 and 1, and in our case we used 0.1 to bring training stability).\n",
    "- `bias`, a single value starting at 0.0.\n",
    "\n",
    "In nutshell, we used `small random values` for `weight` so that all neurons will not learn the same features during training(since weights are not identical). So this randomness will give `neuron` a good starting point which is crucial for learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573510ec-f08f-4758-8f75-385f5d52643e",
   "metadata": {},
   "source": [
    "## Forward Pass implementation\n",
    "\n",
    "Let's check our minds, right? What a h*ll is `Forward Pass`? Hope you remember the mathematical notation of how `artificial neuron` will be working, if yes then `Forward Pass` is all about calculating the neuron's output when given inputs, simply the actual implementation of the previous math notations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a1724a-2bf1-4c63-98af-de571753be2f",
   "metadata": {},
   "source": [
    "```\n",
    "def forward(self, inputs):\n",
    "    \"\"\"\n",
    "    Calculate the neuron's output (weighted sum + bias).\n",
    "    inputs: A NumPy array of input features (must match n_inputs).\n",
    "    \"\"\"\n",
    "    # Input validation ensures our calculations will work correctly\n",
    "    if inputs.shape[0] != self.weights.shape[0]:\n",
    "        raise ValueError(\n",
    "            f\"Input size {inputs.shape[0]} does not match neuron's \"\n",
    "            f\"expected input size {self.weights.shape[0]}.\"\n",
    "        )\n",
    "    \n",
    "    # Calculate the weighted sum using NumPy's optimized dot product function\n",
    "    weighted_sum = np.dot(inputs, self.weights)\n",
    "    \n",
    "    # Add the bias term to get the final output\n",
    "    output = weighted_sum + self.bias\n",
    "    return output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87f3926-91dc-4396-a7b6-2af5c5a9f10d",
   "metadata": {},
   "source": [
    "Our `forward` method is the heart of our neuron. It takes an array of the input and then validate if it has the correct number of elements (shapes) and then calculate the `weighted sum` using `np.dot()`(which is the best for dot product than writing loops); and finally add the bias to get the final output value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a86cbdd-b34a-4a49-b05d-423c0a2e33ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
